\documentclass[a4paper,11pt]{scrartcl}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{ngerman}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{listings}
\usepackage{color}
\usepackage[hyphens]{url}
\usepackage{hyperref}
\usepackage{amssymb} % mathbb
\usepackage{amsmath}% http://ctan.org/pkg/amsmath

\newcommand{\zB}{\mbox{z.\,B.}\xspace}
\newcommand{\bspw}{\mbox{bspw.}\xspace}
\newcommand{\bzw}{\mbox{bzw.}\xspace}
\newcommand{\iAllg}{\mbox{i.\,Allg.}\xspace}
\newcommand{\ua}{\mbox{u.\,a.}\xspace}
\newcommand{\vs}{\mbox{vs.}\xspace}
\newcommand{\inkl}{\mbox{inkl.}\xspace}

\def\CC{{C\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}}
\def\GPP{{G\nolinebreak[4]\hspace{-.05em}\raisebox{.4ex}{\tiny\bf ++}}}
\setlength{\parindent}{0em} % Einrückung verhindern

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

% \fontfamily{pzc}\selectfont
% \ttfamily

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}; should come as last argument
  basicstyle=\footnotesize\fontfamily{bch}\selectfont,        
  % the size & type of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={min,max},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=C,                 % the language of the code
  morekeywords={},                 % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=1,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
%   title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  
\title{\includegraphics[width=0.6\textwidth]{bilder/tuc-logo-black.pdf}
\\Effiziente Implementierung von Matrix-Algorithmen für Multicore-Systeme
}
\subtitle{Praktikum Forschungsschwerpunkt Parallele und verteilte Systeme}
\author{Autor: Matthias Tietz}


\begin{document}

\maketitle \thispagestyle{empty}

\newpage
%%% Informationen/Leerseite %%%
\thispagestyle{empty}
~
\vfill
Technische Universität Chemnitz\\
Fakultät für Informatik\\
Professur Praktische Informatik\\
Praktikum Forschungsschwerpunkt Parallele und verteilte Systeme\\
Wintersemester 2016/2017\\

Effiziente Implementierung von Matrix-Algorithmen für Multicore-Systeme\\
Autor: Matthias Tietz\\
Matrikelnummer:~375681\\
Bachelor Informatik, 5.~Fachsemester

\newpage \tableofcontents
\newpage

\section{Einleitung}\label{chp:Einleitung}
Matrix-Algorithmen finden in einer Vielzahl verschiedener Bereiche Anwendung.
So werden \bspw in der linearen Algebra häufig Matrizen eingesetzt um linearere Gleichungssysteme oder Eigenwertprobleme zu lösen. Im Kontext linearer Abbildungen lassen sich geometrische Transformationen
durch Matrizenprodukte abbilden, was als Grundlage für die Computergrafik zur Realisierung von Koordinatentransformationenen dient.\newline

Der naive Standardalgorithmus zur Matrixmultiplikation 
$C\,= A \cdot B$ mit $A \in \mathbb{R}^{l \times m}$, $B \in \mathbb{R}^{m \times n}$,
$C \in \mathbb{R}^{l \times n}$ verfügt über eine kubische Laufzeit, für jedes Element $c$ der 
Ergebnismatrix $C$ müssen die Werte eines Zeilenvectors von $A$ mit den Werten eines Spaltenvectors
von $B$ schrittweise multipliziert und in $c$ aufsummiert werden. Die Ergebnismatrix $C$
hat die Dimensionen $l \times n$ und für jedes Element aus $C$ entsteht ein linearer Aufwand
$m \Rightarrow$ $\mathcal{O}(m \cdot l \cdot n)$.\newline

Der Algorithmus ist also einfach aufgebaut, es finden nur mathematisch grundlegende Operationen
(Multiplikation, Addition) statt, jedoch in einer großen Anzahl. 
Desweiteren werden die Werte aus
den Ausgangsmatrizen mehrfach verwendet, um \bspw die erste Zeile der Ergebnismatrix $C$ zu berechnen,
benötigen wir für jedes einzelne Element $c$ den gleichen Zeilenvector aus $A$, das gilt für die
Spaltenvectoren von $B$ analog.\newline

Aus den genannten Gründen ergibt sich das Potenzial, das Vorgehen bei der Matrixmultiplikation
zu verbessern. So könnte man die for()-Schleifen so umstrukturieren, dass man diese in kleinere
Iterationsblöcke aufteilt und damit vom Lokalitätsprinzip Gebrauch macht. Ein weiterer Ansatz wäre
ein paralleles Verfahren, um den Zeitaufwand zu minimieren, in dem mehrere Operationen in einem
Schritt ausgeführt werden.

\section{Implementierung}
Bei der Umsetzung der Matrix-Algorithmen ist in erster Linie die Performance-Verbesserung 
von Bedeutung, daher wurde bei der Implementierung kaum Wert auf eine besonders
gute Benutzerfreundlichkeit, umfassende Parameterprüfung oder Tests gelegt --
man geht davon aus, dass der Nutzer korrekte Eingabewerte verwendet.\newline

Zu Beginn der Implementierung hatte ich für die Matrizen einen Datentyp als
\texttt{struct} definiert, was sich aber als unnötig herausgestellt hat, der
Code sollte auf das Notwendige reduziert sein. Daher werden die einzelnen 
Matrizen einfach als float-Array umgesetzt. Zur Vereinfachung der verschiedenen
Verfahren wurde eine Einschränkung auf quadratische Matrizen ($n \times n$) 
und Parametergrößen für $n$ als Zweierpotenzen vorgenommen.\newline

Mit dem Ziel der Optimierungen, wird auch bewusst auf einen guten Coding-Stil verzichtet,
so werden in den performancerelevanten Bereichen unnötige Funktionsaufrufe oder Variablen vermieden, was einen schlechter lesbaren Code zur Folge hat. So wird \bspw anstatt einer
Hilfsfunktion zum Setzen eines Wertes in einer bestimmten Matrix

\lstinputlisting[language=C]{code/set.c}
direkt \texttt{result[(N * i) + j] = value;} verwendet.\newline

Die Ausgangsmatrizen $A$ und $B$
werden vor Benutzung in den verschiedenen Verfahren mit pseudo-zufälligen Werten initialisert
(\texttt{float$*$ createRandomizedMatrix\_f(int N);}), da die konkreten Werte nicht von großer Bedeutung sind, sollte dieses Vorgehen ausreichend sein. Die Ergebnismatrizen werden außerhalb des eigentlichen
Algorithmus mit Nullen initialisiert (\texttt{calloc()}). Das Repository \inkl einer kleinen
Beschreibung ist auf GitHub \cite{ghub} frei verfügbar.


\subsection{Standardalgorithmus}
Der Standardalgorithmus birgt keine großen Überraschungen und wurde in Anlehnung auf die 
Gleichung aus der Aufgabenstellung umgesetzt. In den beiden äußeren Schleifen 
wird über die Zeilen und Spalten der Ergebnismatrix \texttt{result} iteriert,
in der innersten Schleife wird dann die Produktsumme der Eingangsmatrizen (\texttt{a, b}) in der
Variable \texttt{calc} gebildet und der Wert anschließend gespeichert.
Einzige Optimierung ist hierbei der direkte Zugriff per Index auf die Matrizen.

\lstinputlisting[language=C]{code/std.c}

\subsection{Cache-optimiertes Verfahren}
Bei dem Cache-optimiertes Verfahren fand die Umsetzung mittels \emph{Loop tiling} statt,
wodurch die Ausführung der Schleifen effizienter wird. Das Loop tiling gliedert die 
Matrizen in kleinere Blöcke, auf denen die Matrixmultiplikation durchgeführt wird.
Dadurch verbleiben Daten, die bald wieder verwendet werden, im schnellen Hauptspeicher der 
CPU (Cache). \newpage

\lstinputlisting[language=C]{code/block.c}

Die Funktionssignatur besteht nun neben den bekannten Matrizen \texttt{a, b} und \texttt{result}
und der Dimension \texttt{N} nun noch zusätzlich aus einem Parameter \texttt{BS} für 
die Blockgröße, in die die Matrizen unterteilt werden sollen.\newline

In den äußeren drei Schleifen (Zeile 4-6) wird dafür gesorgt, dass der korrekte Offset eingehalten wird,
sodass anstatt direkt über die komplette Dimension \texttt{N} der Matrizen zu iterieren, nur auf den
kleinen Blöcken der Größe \texttt{BLOCK} gearbeitet wird. Daher gilt zu beachten, dass die Indexvariablen
\texttt{i,~j} und \texttt{k} nicht einfach inkrementiert werden wie bei herkömmlichen Schleifen,
sondern um den Offset-Wert \texttt{BLOCK} erhöht werden. Daher auch die Forderung, dass 
die Parametergrößen als Zweierpotenz zu wählen sind, sodass $N \bmod BS = 0$, sich also jede 
Matrix restlos in Blöcke unterteilen lässt.\newline

Die inneren Schleifen (Zeile 8-12) führen dann für die einzelnen Blöcke eine reguläre 
Matrixmultiplikation aus. Hier bekommen die inneren Schleifenvariablen \texttt{y, x, z} den korrekten 
Startpunkt aus \texttt{i, j, k} übergeben und durchlaufen dann anhand der jeweiligen 
Schleifenabbruchbedingung die Berechnungen auf Matrizen der Größe \texttt{BLOCK} $\times$ \texttt{BLOCK}.

\subsection{Paralleles Verfahren}
Wie bereits in der Einleitung~\ref{chp:Einleitung} erwähnt, ist für die 
Matrizenmultiplikation eine große Anzahl gleichartiger Rechenoperationen notwendig.
Daher ergibt sich die Möglichkeit, diese Eigenschaft der Parallelisierbarkeit auszunutzen,
also mehrere Daten quasi-parallel zu bearbeiten.\newline

Um dieses Vorhaben umzusetzen, bieten sich die Advanced Vector Extensions (AVX) an,
welche eine Befehlssatz-Erweiterung für Mikroprozessoren darstellt. Diese Prozessoren
verfügen über SIMD-Erweiterungen (Register, Instruktionen), die es ermöglichen mit einem Befehlsaufruf  mehrere einheitliche Datensätze parallel zu verarbeiten. Um diese Funktionalitäten auf 
Hochsprachen-Ebene zu verwenden, können mithilfe von intrinsischen Funktionen 
die prozessorspezifischen Befehle als normale Funktionsaufrufe abstrahiert werden,
Unterstützung dafür bieten verschiedene Compiler. Eine gute Übersicht über die sogenannten
\emph{Intrinsics} findet man auf der Website von Intel \cite{intr}.\newline

Die relevanten Funktionen, um die Matrixmultiplikation mithilfe von AVX umzusetzen,
umfassen mindestens die Möglichkeiten Werte aus einer Matrix laden/speichern
und Additionen/Multiplikationen ausführen zu können. Da die bisherigen Matrizen auch auf 
float-Werten basieren, kommen für die Berechnungen float-Vectoren (\texttt{\_\_m256}) zum
Einsatz, welche eine Kapazität von 256 Bit bereitstellen und damit 8 floats speichern
können. Hier eine Übersicht über die in meiner Implementierung benutzten Funktionen:\newline

\begin{tabular}{| l | l |}
\hline
Name & Beschreibung \\ \hline
  
\texttt{void \textbf{\_mm256\_storeu\_ps}} & speichert einen 256-bit-Vector \texttt{a} an der Stelle\\
\texttt{(float$*$ mem\_addr, \_\_m256 a)} &  \texttt{mem\_addr} ab   \\ \hline

\texttt{\_\_m256 \textbf{\_mm256\_add\_ps}} & addiert die Elemente der Vectoren \texttt{a} und 
\texttt{b} \\
\texttt{(\_\_m256 a, \_\_m256 b)} & und gibt den Ergebnisvector zurück \\ \hline

\texttt{\_\_m256 \textbf{\_mm256\_mul\_ps}} & multipliziert die Elemente der Vectoren \texttt{a} und \texttt{b} \\
\texttt{(\_\_m256 a, \_\_m256 b)} & und gibt den Ergebnisvector zurück \\ \hline

\texttt{\_\_m256 \textbf{\_mm256\_set1\_ps} (float a)} & erstellt einen Vector, dessen Elemente alle den 
\\
& Wert aus \texttt{a} erhalten \\ \hline

\texttt{\_\_m256 \textbf{\_mm256\_loadu\_ps}} & lädt die Werte aus \texttt{mem\_addr} in einen Vector und \\
\texttt{(float const$*$ mem\_addr)} & gibt diesen zurück \\ \hline
\end{tabular}\newline

Durch Einbinden des Headers \texttt{<immintrin.h>} stehen alle AVX-Funktionen bereit.


% Implementierung
\lstinputlisting[language=C]{code/avx.c}
In der Funktionssignatur tauchen wieder die drei bekannten Matrizen und die Dimension \texttt{N} auf.
Für die Größe der Vectoren im AVX-Verfahren wurde eine globale Variable \texttt{AVX\_VECTOR\_SIZE} ($=8$)
eingeführt, der Algorithmus für dieses Verfahren richtet sich direkt nach dieser Größeneinteilung.
AVX bietet die Datenstruktur der Vectoren (\texttt{\_\_m256}, single-precision) und dafür definierte Funktionen an, wodurch (Rechen-)Operationen auf 8 Datensätzen gleichzeitig vollzogen werden können.
\newline

Die äußerste Schleife (Zeile 4) dient zur Iteration über die Zeilen der Matrix \texttt{a}
und zur Bestimmung der Position zum Speichern des Ergebnisvectors in \texttt{result}.
Um die Anzahl der notwendigen Zwischenberechnungen abzuspeichern, dient die Variable
\texttt{calculation\_count}. Die Matrix \texttt{b} hat eine Spaltenzahl von \texttt{N},
so lässt sich diese durch die Vectorlänge in \texttt{N}$/8$ einteilen, da die Werte aus 
$8$ verschiedenen Spalten in einem Vector abgelegt werden.\newline

Die Schleife in Zeile 7 iteriert nun über diese Einteilung und bestimmt die finale Position zum 
Speichern des Ergebnisvectors. In der innersten Schleife (Zeile 11) findet nun die eigentliche
Berechnung mittels AVX statt. Hier wird für Matrix \texttt{a} aus jeder einzelnen Spalte
\texttt{k} (Einteilung \texttt{N})
aus Zeile \texttt{i} ein broadcast-Vector\footnote{\texttt{\_\_m256 \_mm256\_set1\_ps (float a)}}
erzeugt, da dieser eine float-Wert sowieso mit mehreren Werten aus Matrix \texttt{b} 
(Zeile \texttt{k}) multipliziert werden muss, daher wird das direkt in einem Schritt erledigt
und das Ergebnis anschließend an der Stelle \texttt{result\_address} aufsummiert.\newline

Um weniger Overhead zu verursachen, wurde in Zeile 12-17 bewusst auf das explizite Speichern von 
Zwischenergebnissen verzichtet. Eine serielle (und besser verständliche) Notation der
Berechnungsvorschrift sieht etwa so aus:

\lstinputlisting[language=C]{code/avx_s.c}

\subsection{BLAS}
Zu Vergleichszwecken sollte eine beliebige BLAS-Bibliothek verwendet werden, welche 
\ua eine hochoptimierte Implementierung für die Matrixmultiplikation bereitstellt.
In diesem Fall habe ich mich für ATLAS \cite{atlas} entschieden -- nach erfolgreicher
Installation und Einbinden des Headers \texttt{<cblas.h>} ist die Schnittstelle zu BLAS
 verfügbar.\newline

% TODO: kürzen?


Um nun wie bei den anderen Verfahren eine Matrixmultiplikation auf float-Werten auszuführen, 
bietet die Bibliothek den Funktionsruf \texttt{cblas\_sgemm(…)} (Single Precision, General Matrix Multiplication) an, wodurch allgemein die Gleichung  $C = \alpha \cdot op(A) \cdot op(B) + 
\beta \cdot C$ \cite{blasqr} umgesetzt wird. Durch Deaktivieren der Operationen $op(X)$ auf den 
Eingabematrizen und Setzen von $\alpha = 1, \beta = 0$ erhält man die gewöhnliche Matrixmultiplikation 
der Form $C\,= A \cdot B$.

\section{Benchmark}
%bezug main ... wiederholungen, etc

Das Benchmarkprogramm wurde im Rahmen der \texttt{main()}-Funktion umgesetzt,
der Code ist so aufgebaut, dass jedes Verfahren (1-4) R$\times$ ausgeführt wird
und aus der benötigten Zeit der Durschnitt gebildet wird. Die notwendigen Parameter
(Matrixgröße, Blockgröße, Wiederholungsanzahl) müssen direkt über die Kommandozeile übergeben werden.
Eine Ausführung mit $N = 1024, BS = 8, R = 5$ sieht dann so aus: \texttt{./a.out 1024 8 5}.
\newline

Um sicherzustellen, dass die Berechnungen der einzelnen Verfahren das gleiche Ergebnis
liefern, wird die Hilfsfunktion \texttt{compareResultMatrices\_f()} eingesetzt, die
die Werte der konkreten Ergebnismatrix mit denen vom Standardalgorithmus vergleicht.
Hier nocheinmal der Hinweis, dass primär der Nutzer für korrekte Eingaben verantwortlich ist, 
grob falsche numerische Werte werden jedoch abgefangen.
Nach erfolgreicher Ausführung aller Verfahren ist dann im Ordner \texttt{result/} eine Textdatei (Name
siehe Konsole) mit den Ergebnissen und zugehörigen Parametern verfügbar. \newline

Als Testsystem kam ein Intel i5-3570K $@$ 3.40GHz zum Einsatz, bei der
Kompilierung des Programms mit dem \texttt{gcc} wurde das Optimierungslevel \texttt{-O2} verwendet.
Jedes Verfahren wird für die unterschiedlichen
Parameter $10 \times$ ausgeführt und aus der benötigten Zeit wurde dann der
Durchschnitt gebildet.


\subsection{Performancemessung und -vergleich}
Es folgen nun die konkreten Messwerte als tabellarische Übersicht.
Für das Cache-optimierte Verfahren wurde jeweils eine feste Blockgröße von $8$ gewählt,
da sich mit diesem Wert eine günstige Rechenzeit ergeben hat.
Im Tabellenkopf ist die jeweils getestete Matrixgröße \texttt{N} abgebildet, in den Spalten
befindet sich die durchschnittlich benötigte Zeit und der Speedup des jeweiligen
Verfahrens in Relation zum Standardalgorithmus.\newline

% kleine, mittlere und große Matrizen


\begin{tabular}{| l | l || l || l || l |}
\hline
N $\diagdown$ Verf. & Std.algor. & Cache-opt. & Parallel (AVX) & BLAS  \\ \hline

64 & 0.474 (ms) & 0.534 (ms) | 0.89$\times$ & 0.177 (ms) | 2.68$\times$ & 0.092 (ms) | 5.15$\times$  \\ \hline

128 & 3.962 (ms) & 3.418 (ms) | 1.16$\times$ & 1.186 (ms) | 3.34$\times$ & 0.427 (ms) | 9.27$\times$  \\ \hline
512 & 0.199 (s) & 0.129 (s) | 1.54$\times$ & 0.068 (s) | 2.94$\times$ & 0.013 (s) | 15.9$\times$  \\ \hline
1024 & 2.078 (s) &  1.074 (s) | 1.94$\times$ & 0.670 (s) | 3.10$\times$ & 0.094 (s) | 21.9$\times$ \\ \hline
2048 & 53.91 (s) & 10.10 (s) | 5.34$\times$ & 10.48 (s) | 5.14$\times$ & 0.743 (s) | 72.5$\times$ \\ \hline
 
		 			

\end{tabular}\newline

% Auswertung???

% Cache anfangs (kleine M.) nicht so gut, holt aber später auf, überholt AVX (2048)
% für kleine Matrizen AVX verh. (2x) nah an BLAS, je größer matrix desto deutlicher unterschied
% von BLAS zu restlichen Verfahren



\subsection{Einfluss der Blockgröße auf Verfahren 2}



\section{Zusammenfassung}
% AVX 512, AVX 2... aber prozessorspez.

\section{Quellen}
\begin{thebibliography}{9}

\bibitem{ghub} \url{https://github.com/matthiastz/FSP-Matrixmultiplikation}, März 2017
\bibitem{intr} \url{https://software.intel.com/sites/landingpage/IntrinsicsGuide}, März 2017
\bibitem{atlas} \url{http://math-atlas.sourceforge.net}, März 2017
\bibitem{blasqr} \url{http://www.netlib.org/blas/blasqr.pdf}, März 2017

\end{thebibliography}


\end{document}
